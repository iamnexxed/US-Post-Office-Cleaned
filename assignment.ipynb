{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               name state  established  stamp_index  coordinates   latitude  \\\n",
      "14           ABAUGH    AR       1928.0          1.0         True  35.781747   \n",
      "163          ACTION    AL       1924.0          5.0         True  33.426775   \n",
      "220           ADAMS    MS       1950.0          1.0         True  32.159874   \n",
      "295        ADELBERT    MO       1922.0          4.0         True  37.970883   \n",
      "467       ALABASTER    AL       1951.0          0.0         True  33.217264   \n",
      "...             ...   ...          ...          ...          ...        ...   \n",
      "166010       ZAMORA    NM       1938.0          2.0         True  35.079570   \n",
      "166013         ZANE    UT       1925.0          5.0         True  37.925250   \n",
      "166022     ZARAGOZA    TX       1925.0          2.0         True  26.680060   \n",
      "166056       ZENIFF    AZ       1922.0          3.0         True  34.577260   \n",
      "166072  ZEPHYR COVE    NV       1930.0          0.0         True  38.985540   \n",
      "\n",
      "         longitude  \n",
      "14      -93.501574  \n",
      "163     -86.735265  \n",
      "220     -90.560654  \n",
      "295     -90.710130  \n",
      "467     -86.824298  \n",
      "...            ...  \n",
      "166010 -106.389100  \n",
      "166013 -113.583300  \n",
      "166022  -98.412510  \n",
      "166056 -110.378200  \n",
      "166072 -119.942900  \n",
      "\n",
      "[4175 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(\"postoffice.csv\")\n",
    "\n",
    "# Define the count value\n",
    "count = 100  # Change this value as needed\n",
    "\n",
    "columns_to_remove = ['duration', 'orig_name', 'orig_county', 'continuous', 'alt_name', 'discontinued', 'county1', 'county2', 'county3',  'id', 'gnis_name', 'gnis_match', 'gnis_county', 'gnis_state', 'gnis_feature_id', 'gnis_feature_class', 'gnis_orig_name', 'gnis_orig_county', 'gnis_latitude', 'gnis_longitude', 'gnis_elev_in_m', 'gnis_dist']\n",
    "\n",
    "# Remove the specified columns\n",
    "df_cleaned = df.drop(columns=columns_to_remove)\n",
    "df_cleaned = df_cleaned.dropna(subset=['latitude', 'longitude', 'established'])\n",
    "\n",
    "# Filter the DataFrame based on the condition\n",
    "df_cleaned = df_cleaned[df_cleaned['established'].apply(lambda x: 2021 - x < count)]\n",
    "\n",
    "print(df_cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with NA values removed. Cleaned data saved to postoffice_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Convert 'duration' and 'established' columns to integers\n",
    "#df_top_1000_recent['duration'] = df_top_1000_recent['duration'].astype(int)\n",
    "df_cleaned['established'] = df_cleaned['established'].astype(int)\n",
    "\n",
    "\n",
    "# Write the cleaned data to a new CSV file\n",
    "df_cleaned.to_csv(\"postoffice_cleaned.csv\", index=False)\n",
    "\n",
    "print(\"Rows with NA values removed. Cleaned data saved to postoffice_cleaned.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State-wise post office data saved to statewise_post_offices.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the cleaned CSV file\n",
    "df_cleaned = pd.read_csv(\"postoffice_cleaned.csv\")\n",
    "\n",
    "# Dictionary mapping short names to long names of states\n",
    "state_names_long = {\n",
    "    'AL': 'Alabama', 'AK': 'Alaska', 'AZ': 'Arizona', 'AR': 'Arkansas', 'CA': 'California',\n",
    "    'CO': 'Colorado', 'CT': 'Connecticut', 'DE': 'Delaware', 'FL': 'Florida', 'GA': 'Georgia',\n",
    "    'HI': 'Hawaii', 'ID': 'Idaho', 'IL': 'Illinois', 'IN': 'Indiana', 'IA': 'Iowa',\n",
    "    'KS': 'Kansas', 'KY': 'Kentucky', 'LA': 'Louisiana', 'ME': 'Maine', 'MD': 'Maryland',\n",
    "    'MA': 'Massachusetts', 'MI': 'Michigan', 'MN': 'Minnesota', 'MS': 'Mississippi', 'MO': 'Missouri',\n",
    "    'MT': 'Montana', 'NE': 'Nebraska', 'NV': 'Nevada', 'NH': 'New Hampshire', 'NJ': 'New Jersey',\n",
    "    'NM': 'New Mexico', 'NY': 'New York', 'NC': 'North Carolina', 'ND': 'North Dakota', 'OH': 'Ohio',\n",
    "    'OK': 'Oklahoma', 'OR': 'Oregon', 'PA': 'Pennsylvania', 'RI': 'Rhode Island', 'SC': 'South Carolina',\n",
    "    'SD': 'South Dakota', 'TN': 'Tennessee', 'TX': 'Texas', 'UT': 'Utah', 'VT': 'Vermont',\n",
    "    'VA': 'Virginia', 'WA': 'Washington', 'WV': 'West Virginia', 'WI': 'Wisconsin', 'WY': 'Wyoming'\n",
    "}\n",
    "\n",
    "# Invert the dictionary to get short names as keys and long names as values\n",
    "state_names_short = {v: k for k, v in state_names_long.items()}\n",
    "\n",
    "# Map short state names to long state names\n",
    "df_cleaned['state_longform'] = df_cleaned['state'].map(state_names_long)\n",
    "\n",
    "# Aggregate number of post offices per state\n",
    "state_post_offices_long = df_cleaned.groupby('state_longform').size().reset_index(name='num_post_offices')\n",
    "\n",
    "# Map long state names back to short state names\n",
    "state_post_offices_long['state'] = state_post_offices_long['state_longform'].map(state_names_short)\n",
    "\n",
    "# Concatenate short and long state names with aggregated number of post offices\n",
    "state_post_offices = pd.concat([state_post_offices_long[['state', 'state_longform', 'num_post_offices']], state_post_offices_long[['state', 'state_longform', 'num_post_offices']]])\n",
    "\n",
    "# Calculate the centroid of each state and save it to the CSV\n",
    "centroid_latitudes = []\n",
    "centroid_longitudes = []\n",
    "\n",
    "for state_longform in state_post_offices['state_longform']:\n",
    "    state_data = df_cleaned[df_cleaned['state_longform'] == state_longform]\n",
    "    centroid_latitude = state_data['latitude'].mean()\n",
    "    centroid_longitude = state_data['longitude'].mean()\n",
    "    centroid_latitudes.append(centroid_latitude)\n",
    "    centroid_longitudes.append(centroid_longitude)\n",
    "\n",
    "state_post_offices['centroid_latitude'] = centroid_latitudes\n",
    "state_post_offices['centroid_longitude'] = centroid_longitudes\n",
    "\n",
    "# Write the aggregated data to a new CSV file\n",
    "state_post_offices.to_csv(\"statewise_post_offices.csv\", index=False)\n",
    "\n",
    "print(\"State-wise post office data saved to statewise_post_offices.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
